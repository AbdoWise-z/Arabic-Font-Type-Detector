{"cells":[{"cell_type":"markdown","metadata":{"id":"FEdUKOMkb-Hc"},"source":["# ðŸ“Š Evaluation Script"]},{"cell_type":"markdown","metadata":{"id":"m0iqW5nGb-He"},"source":["Let's start by reading the data"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22131,"status":"ok","timestamp":1715276058234,"user":{"displayName":"Essam Wisam Fouad","userId":"16730529224092958775"},"user_tz":-180},"id":"VbKXtKgVb-Hf","outputId":"c8219e7e-4964-43bd-f23b-1e47525d6804"},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of x_data: (0,) shape of y_data: (0,)\n"]},{"ename":"AssertionError","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_test)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of x_data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_test\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of y_data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(y_test) \u001b[38;5;241m==\u001b[39m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m}\n","\u001b[1;31mAssertionError\u001b[0m: "]}],"source":["# DO NOT CHANGE\n","import cv2\n","import numpy as np\n","import glob\n","import time\n","\n","## 1. Fill x_test and y_test:\n","x_test = []\n","y_test = []\n","fonts = [ 'IBM Plex Sans Arabic', 'Lemonada', 'Marhey', 'Scheherazade New']\n","\n","for font in fonts:\n","    # i = 0 # I was just testing before the submission ..\n","    for filename in sorted(glob.glob(f'content/test/{font}/*.jpeg')):\n","        img = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n","        x_test.append(img)\n","        y_test.append(fonts.index(font))\n","        # i = i + 1\n","        # if (i > 20): break\n","\n","# 2. Convert them to Numpy arrays:\n","x_test = np.asarray(x_test)\n","y_test = np.asarray(y_test)\n","\n","print(\"shape of x_data:\", x_test.shape, \"shape of y_data:\", y_test.shape)\n","assert set(y_test) == {0, 1, 2, 3}"]},{"cell_type":"markdown","metadata":{"id":"7U7oiHOEb-Hg"},"source":["Here you define your predict function following this specific interface:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"yjGpsLkXb-Hg"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading files ..\n","Preparing Kmeans (Bag of words)\n","Loaded\n","Loaded\n"]}],"source":["'''\n","This function takes an RGB image of dimensions (1181, 1181, 3) from the test set and returns integer prediction âˆˆ {0,1,2,3}\n","'''\n","import cv2\n","from sklearn.cluster import KMeans\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.svm import SVC \n","from sklearn.model_selection import train_test_split\n","import os\n","import numpy as np\n","from xgboost import XGBClassifier\n","from cv2.xfeatures2d import SIFT_create as sift_create\n","import pickle\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.decomposition import PCA\n","\n","# utility functions\n","def image_preprocess(img):\n","    #img = cv2.resize(img, (512, 512))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # img = cv2.GaussianBlur(img, (3, 3), 0.1)\n","    img = cv2.medianBlur(img, 3)  # Kernel size can be adjusted as needed\n","    histogram = cv2.calcHist([img], [0], None, [256], [0, 256])\n","    bg_color = np.argmax(histogram)\n","\n","    thresh = 0\n","    if bg_color < 50:  # If the background is brighter than a threshold, invert\n","        _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n","    else:\n","        _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n","    return thresh\n","\n","def apply_pca(descriptors, n_components=64):\n","    pca = PCA(n_components=n_components)\n","    descriptors_reduced = pca.fit_transform(descriptors)\n","    return descriptors_reduced\n","\n","def create_image_histogram(img, kmeans):\n","  descriptors = extract_features(img)[1]\n","  return create_histogram(descriptors , kmeans)\n","\n","def extract_features(img):\n","  surf = sift_create()\n","  keypoints, descriptors = surf.detectAndCompute(img, None)\n","  return keypoints, descriptors\n","\n","def create_histogram(features , kmeans , kmeans_sets = 360):\n","  histogram = np.zeros(kmeans_sets)\n","  if (features is None or len(features) == 0):\n","    return histogram\n","  # descriptors_reduced = apply_pca(features, n_components=64)  # Apply PCA\n","  prediction = kmeans.predict(features)\n","  for p in prediction:\n","    histogram[p] += 1\n","  return histogram\n","\n","def classify_image(img, kmeans, clf):\n","  img = image_preprocess(img)\n","  histogram = create_image_histogram(img, kmeans)\n","  predictions = clf.predict([histogram])\n","  return predictions[0]\n","\n","classifier_path = \"models/classifier_ada.pkl\"\n","kmeans_path     = \"models/kmeans_model.pkl\"\n","kmeans = None\n","clf = None\n","\n","print(\"Loading files ..\")\n","print(\"Preparing Kmeans (Bag of words)\")\n","with open(kmeans_path, 'rb') as f:\n","    kmeans = pickle.load(f)\n","if kmeans is not None:\n","    print(\"Loaded\")\n","else:\n","    print(\"Failed to Load\")\n","\n","with open(classifier_path, 'rb') as f:\n","    clf = pickle.load(f)\n","if clf is not None:\n","    print(\"Loaded\")\n","else:\n","    print(\"Failed to Load\")\n","\n","if kmeans is None or clf is None:\n","    print(\"Error loading files\")\n","    \n","def make_prediction(x):\n","    return classify_image(x , kmeans , clf)\n","\n","# Fill your team number here\n","TEAM_NUM = \"14\""]},{"cell_type":"markdown","metadata":{"id":"u3l-tP0Yb-Hh"},"source":["Now let's compute the accuracy of the model:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2JZiig46b-Hh","outputId":"8ad9b236-344e-49a1-f833-58f18d28b452"},"outputs":[{"name":"stdout","output_type":"stream","text":["Team 14 got accuracy: 100.00%\n","Team 14 got runtime: 1737.98%\n"]}],"source":["# DO NOT CHANGE\n","y_pred = []\n","\n","start_time = time.time()\n","for x in x_test:\n","    assert x.shape == (1181, 1181, 3)\n","    yÌ‚ = make_prediction(x)\n","    y_pred.append(yÌ‚)\n","end_time = time.time()\n","\n","y_pred = np.asarray(y_pred)\n","accuracy = np.mean(y_pred == y_test)\n","total_time = end_time - start_time\n","print(f\"Team {TEAM_NUM} got accuracy: {accuracy:.2%}\")\n","print(f\"Team {TEAM_NUM} got runtime: {total_time:.2%}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
